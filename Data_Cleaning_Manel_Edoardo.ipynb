{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing missing values...\n",
      "                           Missing Values  Percentage\n",
      "Open_fire                           24851   96.020247\n",
      "Surface_of_the_Land                 20299   78.432054\n",
      "Garden                              20299   78.432054\n",
      "Garden_Area                         20299   78.432054\n",
      "Swimming_Pool                       16527   63.857656\n",
      "Terrace_Area                        15701   60.666126\n",
      "Furnished                           14784   57.122986\n",
      "Disabled_Access                     14355   55.465399\n",
      "Surface_area_plot_of_land           12684   49.008925\n",
      "Lift                                10965   42.366987\n",
      "Terrace                              9378   36.235076\n",
      "Number_of_Facades                    8658   33.453112\n",
      "State_of_the_Building                5279   20.397203\n",
      "Living_Area                          2373    9.168888\n",
      "Price                                1485    5.737800\n",
      "Number_of_Rooms                      1484    5.733936\n",
      "Locality                                0    0.000000\n",
      "Fully_Equipped_Kitchen                  0    0.000000\n",
      "Subtype_of_Property                     0    0.000000\n",
      "Type_of_Property                        0    0.000000\n",
      "province                                0    0.000000\n",
      "Municipality                            0    0.000000\n",
      "Dropping columns with more than 5.0% missing data: ['Open_fire', 'Surface_of_the_Land', 'Garden', 'Garden_Area', 'Swimming_Pool', 'Terrace_Area', 'Furnished', 'Disabled_Access', 'Surface_area_plot_of_land', 'Lift', 'Terrace', 'Number_of_Facades', 'Living_Area']\n",
      "Removing outliers from columns: ['Price', 'Number_of_Rooms']\n",
      "Cleaned dataset saved to immoweb_data_cleaned_combined.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_dataset_with_analysis(file_path, output_path, drop_threshold=0.05):\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Analyze missing values\n",
    "        print(\"Analyzing missing values...\")\n",
    "        missing_data = df.isnull().sum()\n",
    "        missing_percentage = (missing_data / len(df)) * 100\n",
    "        missing_info = pd.DataFrame({\n",
    "            'Missing Values': missing_data,\n",
    "            'Percentage': missing_percentage\n",
    "        }).sort_values(by='Percentage', ascending=False)\n",
    "        print(missing_info)\n",
    "\n",
    "        # Define critical columns that should not be dropped\n",
    "        critical_columns = ['Price', 'Type_of_Property', 'Locality', 'Number_of_Rooms', 'State_of_the_Building']\n",
    "        \n",
    "        # Drop columns with > drop_threshold missing data, excluding critical columns\n",
    "        threshold = drop_threshold * len(df)\n",
    "        columns_to_drop = [\n",
    "            col for col in missing_info[missing_info['Missing Values'] > threshold].index\n",
    "            if col not in critical_columns\n",
    "        ]\n",
    "        print(f\"Dropping columns with more than {drop_threshold * 100}% missing data: {columns_to_drop}\")\n",
    "        df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "        # Drop rows where critical columns have missing values\n",
    "        df = df.dropna(subset=[col for col in critical_columns if col in df.columns])\n",
    "\n",
    "        # Fill missing values for categorical data with mode based on grouped data\n",
    "        def get_grouped_mode(dataframe, group, column):\n",
    "            mode_dict = dataframe.groupby(group)[column].apply(pd.Series.mode).to_dict()\n",
    "            return {key: mode_dict[key] for key in mode_dict if not mode_dict[key].empty}\n",
    "        \n",
    "        # Handle 'Lift' if it exists in the dataset\n",
    "        if 'Lift' in df.columns and 'Subtype_of_Property' in df.columns:\n",
    "            lift_dict = get_grouped_mode(df, 'Subtype_of_Property', 'Lift')\n",
    "            df['Lift'] = df['Lift'].fillna(df['Subtype_of_Property'].map(lift_dict))\n",
    "            print(f\"Lift grouped mode: {lift_dict}\")\n",
    "\n",
    "        # Price grouping\n",
    "        price_bins = list(range(0, 300000, 100000)) + \\\n",
    "                     list(range(350000, 1100000, 200000)) + \\\n",
    "                     list(range(1100000, 3000000, 1000000)) + [float('inf')]\n",
    "        price_labels = [\n",
    "            f\"{price_bins[i]}-{price_bins[i + 1]}\" if price_bins[i + 1] != float('inf') else f\"{price_bins[i]}+\"\n",
    "            for i in range(len(price_bins) - 1)\n",
    "        ]\n",
    "        df['Price_Group'] = pd.cut(df['Price'], bins=price_bins, labels=price_labels, include_lowest=True)\n",
    "\n",
    "        if 'province' in df.columns:\n",
    "            df[\"Price_Group_Per_Region\"] = df['province'] + '_' + df[\"Price_Group\"].astype(str)\n",
    "            if 'State_of_the_Building' in df.columns:\n",
    "                state_mode_dict = df.groupby('Price_Group_Per_Region')['State_of_the_Building'].apply(\n",
    "                    lambda x: x.mode().iloc[0] if not x.mode().empty else None\n",
    "                ).to_dict()\n",
    "                df[\"State_of_the_Building\"] = df[\"State_of_the_Building\"].fillna(df['Price_Group_Per_Region'].map(state_mode_dict))\n",
    "        \n",
    "        # Handle 'Number_of_Facades' based on median grouped by 'Subtype_of_Property'\n",
    "        if 'Subtype_of_Property' in df.columns and 'Number_of_Facades' in df.columns:\n",
    "            nb_of_facades_dict = df.groupby('Subtype_of_Property')['Number_of_Facades'].median().to_dict()\n",
    "            df['Number_of_Facades'] = df['Number_of_Facades'].fillna(df['Subtype_of_Property'].map(nb_of_facades_dict))\n",
    "\n",
    "        # Replace missing values for 'Surface_area_plot_of_land' with 0\n",
    "        if 'Surface_area_plot_of_land' in df.columns:\n",
    "            df['Surface_area_plot_of_land'] = df['Surface_area_plot_of_land'].fillna(0)\n",
    "\n",
    "        # Fill numerical columns with median\n",
    "        for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "        \n",
    "        # Fill categorical columns with mode\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        \n",
    "        # Remove outliers using IQR\n",
    "        def remove_outliers(data, columns):\n",
    "            for col in columns:\n",
    "                if col in data.columns:\n",
    "                    Q1 = data[col].quantile(0.25)\n",
    "                    Q3 = data[col].quantile(0.75)\n",
    "                    IQR = Q3 - Q1\n",
    "                    lower_bound = Q1 - 1.5 * IQR\n",
    "                    upper_bound = Q3 + 1.5 * IQR\n",
    "                    data = data[(data[col] >= lower_bound) & (data[col] <= upper_bound)]\n",
    "            return data\n",
    "        \n",
    "        numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "        print(f\"Removing outliers from columns: {list(numerical_columns)}\")\n",
    "        df = remove_outliers(df, numerical_columns)\n",
    "\n",
    "        # Save the cleaned dataset\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Cleaned dataset saved to {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "clean_dataset_with_analysis('immoweb_data_final.csv', 'immoweb_data_cleaned_combined.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
